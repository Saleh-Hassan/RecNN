{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Determenistic Policy Gradients\n",
    "Work in progress nut it will be finished soon enough\n",
    "\n",
    "Special thanks to KnightofK9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "\n",
    "cuda = torch.device('cuda')\n",
    "frame_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../data/ml-20m/ratings.csv')\n",
    "movies = pickle.load(open('../data/infos.pytorch', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits: KnightofK9\n",
    "ratings[\"rating\"] = ratings[\"rating\"].apply(lambda i: 2 * (i - 2.5))\n",
    "users = ratings[[\"userId\",\"movieId\"]].groupby([\"userId\"]).size()\n",
    "users = users[users >= frame_size + 1]\n",
    "ratings = ratings[ratings[\"userId\"].isin(users.index)]\n",
    "ratings = ratings.sort_values(by=[\"userId\", \"timestamp\"]).drop(columns=[\"timestamp\"]).set_index(\"userId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in movies.keys():\n",
    "    movies[i] = movies[i].to(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = nn.Sequential(nn.Linear(2591, 64), nn.Tanh()).to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateRepresentation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StateRepresentation, self).__init__()\n",
    "        self.lin = nn.Sequential(\n",
    "            # 64 - embed size, 1 - rating size\n",
    "            nn.Linear(frame_size * (64 + 1), 128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, info, ratings):\n",
    "        # raw_size - size of the raw movie info. Constant = 2591\n",
    "        # embed_size - size of an ebedded movie. Constant = 64\n",
    "        # raw -> embed via embeddings module defined above\n",
    "        # input: currently info is batch_size x frame_size x raw_size\n",
    "        # step 1: transform info to (batch_size * frame_size) x raw_size\n",
    "        info = info.view(-1, 2591)\n",
    "        # step 2: apply embeddings, map info to (batch_size * frame_size) x embed_size\n",
    "        info = embeddings(info)\n",
    "        # step 3: transform info back to batch_size x frame_size x raw_size\n",
    "        info = info.view(batch_size, frame_size, 64)\n",
    "        # step 4: tramsform info to batch_size x (frame_size * embed_size)\n",
    "        info = info.view(batch_size, frame_size * 64)\n",
    "        # step 5: stack info with ratings. stacked: batch_size x (embed_size + 1)\n",
    "        stacked = torch.cat([info, ratings], 1)\n",
    "        # step 6: apply state represemtation module\n",
    "        state = self.lin(stacked)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = StateRepresentation().to(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_batch(batch):\n",
    "    watched_infos = []\n",
    "    watched_rating = []\n",
    "    chosen_movie = []\n",
    "    chosen_rating = []\n",
    "    \n",
    "    for b in batch:\n",
    "        watched_infos.append(b[0][0])\n",
    "        watched_rating.append(torch.from_numpy(b[0][1]))\n",
    "        chosen_movie.append(b[1])\n",
    "        chosen_rating.append(b[2])\n",
    "                    \n",
    "    watched_infos = torch.stack(watched_infos).to(cuda)\n",
    "    watched_rating = torch.stack(watched_rating).float().to(cuda)\n",
    "    chosen_movie = torch.stack(chosen_movie).to(cuda)\n",
    "    chosen_rating = torch.tensor(chosen_rating).to(cuda)\n",
    "    \n",
    "    return (watched_infos, watched_rating), chosen_movie, chosen_rating\n",
    "\n",
    "batch_bar = tqdm(total=len(users))\n",
    "batch = []\n",
    "batch_size = 100\n",
    "for user, df in ratings.groupby(level=0):\n",
    "    batch_bar.update(1)\n",
    "    size = max(len(df) - frame_size, 0)\n",
    "    for idx in range(0, size):\n",
    "        \n",
    "        if np.random.rand() < 0.8:  # intake percents\n",
    "            continue\n",
    "            \n",
    "        user_ratings = df[idx:frame_size + idx + 1]\n",
    "        user_ratings = user_ratings[[\"movieId\", \"rating\"]].values\n",
    "\n",
    "        chosen_movie = user_ratings[:, 0][-1] \n",
    "        chosen_movie = movies[chosen_movie] # action\n",
    "        chosen_rating = user_ratings[:, 1][-1] # reward\n",
    "        films_watched = user_ratings[:, 0][:-1] \n",
    "        watched_rating = user_ratings[:, 1][:-1] # state\n",
    "        watched_infos = [movies[i] for i in films_watched] # state\n",
    "        watched_infos = torch.stack(watched_infos)    \n",
    "        # state action reward\n",
    "        batch.append([(watched_infos, watched_rating), chosen_movie, chosen_rating])\n",
    "                \n",
    "        if len(batch) >= batch_size:\n",
    "            # train here\n",
    "            batch = prepare_batch(batch)\n",
    "            sr(*batch[0]).size()\n",
    "            batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
