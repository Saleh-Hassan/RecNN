{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "I started working on an async generator. Id doesn't seem to be working fast (~5 times slower). If you have any suggstions, please commit because it can improve performance up to 4 times and take only 10 minutes to run instead of 40 (I have I5 4460)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from aiostream import stream\n",
    "\n",
    "async def batch_worker(ratings, intake, batch_size=25):\n",
    "    while 1:\n",
    "        \n",
    "        batch_bar = tqdm(total=len(users))\n",
    "        b = []\n",
    "        for user, df in ratings.groupby(level=0):\n",
    "            batch_bar.update(1)\n",
    "            size = max(len(df) - frame_size, 0)\n",
    "            for idx in range(0, size):\n",
    "                if np.random.rand() < intake:  # intake percents\n",
    "                    continue\n",
    "                user_ratings = df[idx:frame_size + idx + 1]\n",
    "                user_ratings = user_ratings[[\"movieId\", \"rating\"]].values\n",
    "\n",
    "                chosen_movie = user_ratings[:, 0][-1] \n",
    "                chosen_movie = movies[chosen_movie] # action\n",
    "                chosen_rating = user_ratings[:, 1][-1] # reward\n",
    "                films_watched = user_ratings[:, 0][:-1] \n",
    "                watched_rating = user_ratings[:, 1][:-1] # state\n",
    "                watched_infos = [movies[i] for i in films_watched] # state\n",
    "                watched_infos = torch.stack(watched_infos)    \n",
    "                # state action reward\n",
    "                b.append([(watched_infos, watched_rating), chosen_movie, chosen_rating])\n",
    "                \n",
    "                if len(b) >= batch_size:\n",
    "                    yield b\n",
    "                    b = []\n",
    "        batch_bar.close()\n",
    "        \n",
    "async def batch_pool(n_workers, intake, batch_size):\n",
    "    m_batch_size = batch_size/n_workers\n",
    "    combine = stream.merge(*[batch_worker(ratings, intake, m_batch_size) for i in range(n_workers)])\n",
    "    batch = []\n",
    "    async with combine.stream() as streamer:\n",
    "        async for m_batch in streamer:\n",
    "            batch.append(m_batch)\n",
    "            # cat all things, process batch\n",
    "            if len(batch) >= n_workers:\n",
    "                \n",
    "                batch_copy = []\n",
    "                \n",
    "                for b in range(int(m_batch_size)):\n",
    "                    for i in range(n_workers):\n",
    "                        batch_copy.append(batch[i][b])\n",
    "                batch = batch_copy\n",
    "                del batch_copy\n",
    "                \n",
    "                yield (watched_infos, watched_rating), chosen_movie, chosen_rating\n",
    "                batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    i = 0\n",
    "    async for batch in batch_pool(4, 0.2, 100):\n",
    "        pass\n",
    "loop = asyncio.get_event_loop()\n",
    "asyncio.run_coroutine_threadsafe(main(), loop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
